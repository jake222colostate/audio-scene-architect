# syntax=docker/dockerfile:1.6
FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04
SHELL ["/bin/bash","-euxo","pipefail","-c"]

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 PYTHONDONTWRITEBYTECODE=1 \
    HF_HOME=/app/.cache/huggingface \
    TRANSFORMERS_CACHE=/app/.cache/huggingface

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv build-essential libsndfile1 ffmpeg curl git ca-certificates \
  && ln -sf /usr/bin/python3 /usr/bin/python && ln -sf /usr/bin/pip3 /usr/bin/pip \
  && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY backend/requirements.txt /app/backend/requirements.txt
COPY backend/requirements-heavy.txt /app/backend/requirements-heavy.txt

# Install light deps first (changes less often)
RUN pip install --no-cache-dir -r /app/backend/requirements.txt
# Install heavy CUDA deps (very large; keep cached)
RUN pip install --no-cache-dir --extra-index-url https://download.pytorch.org/whl/cu121 \
    -r /app/backend/requirements-heavy.txt

RUN python - <<'PY'
import torch
print("Torch:", torch.__version__, "CUDA:", getattr(torch.version,'cuda',None), "cuda.is_available:", torch.cuda.is_available())
PY
